{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "210bb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yfinance as yf\n",
    "from sec_cik_mapper import StockMapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d4bb4",
   "metadata": {},
   "source": [
    "The JSON files come in two main partitions (need to find out exactly what they mean)\n",
    "\n",
    "- DEI\n",
    "\n",
    "- US-GAAP\n",
    "\n",
    "General Structure of the JSON file:\n",
    "\n",
    "- [Partition]\n",
    "    - Heading Name\n",
    "        - Label (more verbose heading)\n",
    "        - Description\n",
    "        - Units\n",
    "            - Unit of Measurement\n",
    "                - ...\n",
    "                - Val\n",
    "                - Form\n",
    "                - Filed (date)\n",
    "                - ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3282fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "minYear = 2023\n",
    "\n",
    "columnNames = ['CIK', 'heading', 'units', 'value', 'frame']\n",
    "# other columns if needed: fy, qtr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c54fa8d",
   "metadata": {},
   "source": [
    "## Read Company Financials JSON file\n",
    "\n",
    "This function takes in a DataFrame (which should just be what is returned by called pd.read_json() on a company's JSON file) and returns another DataFrame with the JSON data transformed into a tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4740a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_company_financials_json(df: pd.DataFrame):\n",
    "    # Pull out the company's name and CIK\n",
    "    entityName = df.iloc[0,1]\n",
    "    entityCIK = str(df.iloc[0,0])\n",
    "    \n",
    "    # Initialise a dataframe to hold the data\n",
    "    companyDF = pd.DataFrame(columns=columnNames)\n",
    "    quarters = {'03': 'Q1', '06': 'Q2', '09': 'Q3', '12': 'Q4'}\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        partitionName = df.index[i]\n",
    "        partitionName = partitionName.upper()\n",
    "        partition = df.iloc[i,2]\n",
    "        subGroups = partition.items()\n",
    "\n",
    "        intermediateDF = pd.DataFrame(columns=columnNames)\n",
    "\n",
    "        if partitionName == 'US-GAAP':\n",
    "            # Each of DEI, invest, US-GAAP is broken down into subgroups\n",
    "            for group in subGroups:\n",
    "                # Each subgroup has a heading, detailed description, and unit of measurement\n",
    "                row = {}\n",
    "                heading = group[0]\n",
    "                # row['company'] = entityName\n",
    "                row['CIK'] = entityCIK\n",
    "                row['heading'] = heading\n",
    "                desc = group[1]['description']\n",
    "\n",
    "                # The units component contains the actual measurement and the associated metadata (in the 'records' list)\n",
    "                units = group[1]['units']\n",
    "                for unit, records in units.items():\n",
    "                    row['units'] = unit\n",
    "\n",
    "                    # We have a record for every filing date\n",
    "                    for record in records:\n",
    "                        periodEndYear, periodEndMonth, _ = record['end'].split('-')\n",
    "                        periodStartYear, periodStartMonth = (0, 0)\n",
    "                        try:\n",
    "                            periodStartYear, periodStartMonth, _ = record['start'].split('-')\n",
    "                        except KeyError: \n",
    "                            pass\n",
    "                        \n",
    "                        if record['form'] == '10-Q' and int(periodEndYear) >= 2018: \n",
    "                            if 'frame' in record.keys():\n",
    "                                row['value'] = round(float(record['val']), 2)\n",
    "                                row['frame'] = record['frame']\n",
    "\n",
    "                                # Append the row to the main dataframe\n",
    "                                nextIdx = len(intermediateDF)\n",
    "                                intermediateDF.loc[nextIdx] = row\n",
    "                            elif (periodEndMonth in quarters.keys() and \n",
    "                                  ((int(periodEndMonth) - int(periodStartMonth)) == 3) and\n",
    "                                  (int(periodEndYear) == periodStartYear)):\n",
    "                                row['value'] = round(float(record['val']), 2)\n",
    "                                row['frame'] = \"CY\" + periodEndYear + quarters[periodEndMonth]\n",
    "\n",
    "                                # Append the row to the main dataframe\n",
    "                                nextIdx = len(intermediateDF)\n",
    "                                intermediateDF.loc[nextIdx] = row                                \n",
    "                            \n",
    "        companyDF = pd.concat([companyDF, intermediateDF], ignore_index=True)\n",
    "                        \n",
    "    return companyDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ae5f1",
   "metadata": {},
   "source": [
    "## Read through each company's JSON file and append to masterDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "166d5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folderPath = '.'\n",
    "folderPath = 'companyfacts/Biggest Files'\n",
    "\n",
    "masterDF = pd.DataFrame(columns=columnNames)\n",
    "dimCompany = pd.DataFrame(columns=['company', 'CIK'])\n",
    "\n",
    "counter = 0\n",
    "for filename in os.listdir(folderPath):\n",
    "    counter += 1\n",
    "    if filename.endswith('.json') and counter < 100:\n",
    "        filePath = os.path.join(folderPath, filename)\n",
    "        df = pd.read_json(filePath)\n",
    "        \n",
    "        entityName = df.iloc[0,1]\n",
    "        entityCIK = str(df.iloc[0,0])\n",
    "        companyIdx = len(dimCompany)\n",
    "        dimCompany.loc[companyIdx] = {'company': entityName, 'CIK': entityCIK}\n",
    "        \n",
    "        companyDF = read_company_financials_json(df)\n",
    "        \n",
    "        masterDF = pd.concat([masterDF, companyDF], ignore_index=True)\n",
    "        \n",
    "        \n",
    "masterDF\n",
    "masterDF.to_csv('testDF.csv', index=False)\n",
    "#dimCompany.to_csv('dimCompany.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e9793",
   "metadata": {},
   "source": [
    "## CIK to Ticker mapping\n",
    "\n",
    "We have all of the company's CIKs from the SEC EDGAR data. This can be mapped to their stock ticker with the sec_cik_mapper package. This ticker can then be mapped to the company's sector and industry with the yfinance API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3af7640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensional table for tickers that can be joined to stock price data\n",
    "dimTickers = pd.DataFrame(columns=[\"ticker\", \"CIK\"])\n",
    "\n",
    "# Dimensional table for mapping companies to their sectors\n",
    "dimSectors = pd.DataFrame(columns=[\"sector\", \"industry\", \"CIK\"])\n",
    "\n",
    "# Create the CIK to ticker mapping from the sec_cik_mapper package\n",
    "mapper = StockMapper()\n",
    "cikToTickers = mapper.cik_to_tickers\n",
    "\n",
    "tickerIdx = 0\n",
    "sectorIdx = 0\n",
    "\n",
    "# Iterate through all companies\n",
    "for i in range(len(dimCompany)):\n",
    "    cik = dimCompany.iloc[i,1]\n",
    "    companyName = dimCompany.iloc[i,0]\n",
    "    \n",
    "    # Find the corresponding ticker for the company's CIK\n",
    "    for key in cikToTickers.keys():\n",
    "        if cik in key:\n",
    "            for ticker in cikToTickers[key]:\n",
    "                if \"-\" not in ticker:\n",
    "                    # Add the CIK and ticker to dimTickers\n",
    "                    dimTickers.loc[tickerIdx] = {\"ticker\": ticker, \"CIK\": cik}\n",
    "                    tickerIdx += 1\n",
    "                    \n",
    "                    # Use yfinance API to get the company's sector/industry with their ticker\n",
    "                    stockInfo = yf.Ticker(ticker).get_info()\n",
    "                    try:\n",
    "                        stockSector = stockInfo[\"sector\"]\n",
    "                    except KeyError:\n",
    "                        stockSector = None\n",
    "                    \n",
    "                    try:\n",
    "                        stockIndustry = stockInfo[\"industry\"]\n",
    "                    except KeyError:\n",
    "                        stockIndustry = None\n",
    "                    \n",
    "                    dimSectors.loc[sectorIdx] = {\"sector\": stockSector, \n",
    "                                                 \"industry\": stockIndustry,\n",
    "                                                 \"CIK\": cik}\n",
    "                    sectorIdx += 1\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e36241d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimTickers.to_csv('dimTickers.csv', index=False)\n",
    "dimSectors.to_csv('dimSectors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f52cf8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
